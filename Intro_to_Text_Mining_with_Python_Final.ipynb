{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqRzv147AgC-"
      },
      "source": [
        "# Intro to Text Mining with Python\n",
        "Hello everyone. My name is Sean Ru. I am a third-year CS major here at the Data Visualization Lab.\n",
        "\n",
        "For today's workshop, we will be using the NLTK library to walk you through some basic steps of a text mining project. NLTK is one of the most popular libraries used to work with human language data.\n",
        "\n",
        "\"Text mining, also referred to as text analysis, is the process of obtaining meaningful information from large collections of unstructured data. By automatically identifying patterns, topics, and relevant keywords, text mining uncovers relevant insights that can help you answer specific questions.\" -monkeylearn.com\n",
        "\n",
        "Some basic steps of text mining we are going to demonstrate include:\n",
        "\n",
        "       -Parsing\n",
        "       -Comparison Methods\n",
        "       -String Operations\n",
        "\n",
        "These basic steps can utilized later on in:\n",
        "\n",
        "       -Complex Parsing\n",
        "       -Text Mining Techniques:\n",
        "          -Information Extraction (process of extracting meaningful information from text data; this includes identifying and extracting entities, their attributes, and their relationships)\n",
        "          -Information Retrieval (process of extracting information based on a particular set of words or phrases; example is Google Search)\n",
        "          -Categorization (form of supervised learning to sort texts into predefined topics; used in NLP)\n",
        "          -Clustering (identify and locate intrinsic structures within a text database and organize them into subgroups for further analysis; big challenge to create meaningful clusters from unclassified text data)\n",
        "          -Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZk46GfSHNWZ"
      },
      "outputs": [],
      "source": [
        "#Note: If you are using Jupyter Notebooks instead of Google Colab to run this file and code, you will need to install different libraries in your command prompt (e.g. pip install)\n",
        "\n",
        "from pathlib import Path #provides an object api for working with files and directories\n",
        "import pandas as pd #library used for data science and machine learning\n",
        "import os #provides functions for interacting with operating systems\n",
        "import glob #used to return all file paths that match a specific pattern\n",
        "import sys #provides functions and variables used to manipulate different part of the Python runtime environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8tYhlKkHSVg"
      },
      "source": [
        "### Import files\n",
        "\n",
        "In order to import a folder of files, we use the os.chdir function to first navigate to the right directory.\n",
        "\n",
        "Then we use glob.glob function to iterate through all files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mah_JBzPHOOo"
      },
      "outputs": [],
      "source": [
        "my_dir = \"Sample_data\"\n",
        "os.chdir(my_dir)   #change the current working directory to specified path. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJA1yMecHaIX"
      },
      "outputs": [],
      "source": [
        "reviewList=[]\n",
        "#code through here\n",
        "for files in glob.glob(\"*.txt\"):   #glob.glob returns a list of pathnames. It helps us loop through all files that are .txt in the sample folder\n",
        "    df = pd.read_csv(files) #dataframe, data structure that organizes data into a 2-dimensional table of rows and columns, like a spreadsheet\n",
        "    #print(df)\n",
        "    for content in df:  \n",
        "        reviewList.append(content) #add all the data (or in this case the strings in the files in sample data) to this list\n",
        "print (reviewList) #see the list of Strings from all the .txt files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-NRp0QTM56Y"
      },
      "source": [
        "Convert the review list into a huge string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEXsipJrM4cc"
      },
      "outputs": [],
      "source": [
        "str1 = \" \" #String that will combine all the strings in the reviewList into 1 huge string, want it as a bag of words\n",
        "data = str1.join(reviewList) #combines all the strings, data is a string\n",
        "#allows us to not have to use anymore loops to do the same function for all the separate strings in the reviewList\n",
        "data = data.replace(\"<br />\",\"\") #deletes any breaks or \\n\n",
        "print (data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AuxFOLb309_"
      },
      "source": [
        "## Parsing\n",
        "\n",
        "Text Parsing is the the task of separating the text we want to analyze into smaller components based on some rules. This is very common in different applications such as document parsing and NLP.\n",
        "\n",
        "### Tokenization\n",
        "Tokenization is the process by which big quantity of text is divided into smaller parts called tokens.\n",
        "\n",
        "### Remove punctuations and Stop Words\n",
        "Stop Words are words that are so commonly used that they carry very little useful information.\n",
        "\n",
        "http://www.nltk.org/nltk_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpcFYiMnNA2o"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "# nltk.download_shell() for mac users\n",
        "from nltk.tokenize import word_tokenize #word is splits a string into individual words called tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWCqOCfPW11F"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "#sp is for stopwords and punctuations\n",
        "tokensp = word_tokenize(data) #fill the periods with spaces.\n",
        "wordsp = [word.lower() for word in tokensp] #lowercase everything and if it isn't a punctuation add it to words\n",
        "print(sorted(wordsp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deoHaO-oNF-k"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(data)\n",
        "print(tokens)\n",
        "words = [word.lower() for word in tokens]\n",
        "print(words)\n",
        "print(sorted(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84YZcOuPNDXG"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords \n",
        "#stopwords are words that can be safely ignored, they don't add much meaning to a sentence outside of grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-skURpXOPYJ6"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) #tell it we want english\n",
        "\n",
        "## Add extra stop words after viewing the results\n",
        "# stop_words.remove(\"yourself\")\n",
        "# print (sorted(stop_words))\n",
        "\n",
        "filtered_wordsp = [word for word in wordsp if not word in stop_words] #if not a stop word, add to filtered_words\n",
        "print(sorted(filtered_wordsp)) #sort it aphabetically\n",
        "filtered_words = [word for word in words if not word in stop_words] #if not a stop word, add to filtered_words\n",
        "print(sorted(filtered_words)) #sort it aphabetically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYHXr02ww46o"
      },
      "outputs": [],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvwC1rHhSUQr"
      },
      "outputs": [],
      "source": [
        "print(set(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEkKbwZgSUVf"
      },
      "outputs": [],
      "source": [
        "len(set(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPNtbYdCTO51"
      },
      "outputs": [],
      "source": [
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X854qbooTSE2"
      },
      "outputs": [],
      "source": [
        "print(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mm2NaE_TTn1"
      },
      "outputs": [],
      "source": [
        "len(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgMrpf5jSz1r"
      },
      "outputs": [],
      "source": [
        "print(set(w.lower() for w in tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzG_SS5LSUZz"
      },
      "outputs": [],
      "source": [
        "len(set(w.lower() for w in tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add annotation about startswith and endswith"
      ],
      "metadata": {
        "id": "c_Vv-NvVImwC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHYHt9cqSUga"
      },
      "outputs": [],
      "source": [
        "print(sorted([w for w in tokens if w.startswith('A')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I90STlsKSUtC"
      },
      "outputs": [],
      "source": [
        "print(sorted([w for w in tokens if w.endswith('a')]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison Methods"
      ],
      "metadata": {
        "id": "jUqc2WVvxDzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isupper()\n",
        "isupper() returns True if all alphabetical characters are uppercased."
      ],
      "metadata": {
        "id": "Pg8kLF8ojRhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#isupper()\n",
        "str1 = \"THWG\"\n",
        "str2 = \"THWG!\"\n",
        "str3 = \"TO HELL WITH GEORGIA!\"\n",
        "str4 = \"To hell with Georgia!\"\n",
        "str5 = \"to hell with georgia!\"\n",
        "print(str1.isupper())\n",
        "print(str2.isupper())\n",
        "print(str3.isupper())\n",
        "print(str4.isupper())\n",
        "print(str5.isupper())"
      ],
      "metadata": {
        "id": "VraI1ajJxscl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### islower()\n",
        "islower() returns True if all alphabetical characters are lowercased."
      ],
      "metadata": {
        "id": "a3ovsvcOjSic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#islower()\n",
        "print(str1.islower())\n",
        "print(str2.islower())\n",
        "print(str3.islower())\n",
        "print(str4.islower())\n",
        "print(str5.islower())"
      ],
      "metadata": {
        "id": "wKdO5qmpxshl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### istitle()\n",
        "istitle() returns True if only the first letters of every word is capitalized, therefore making the String at Title."
      ],
      "metadata": {
        "id": "qlVXcn0djTPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#istitle()\n",
        "str6 = \"To Hell the Georgia!\"\n",
        "str7 = \"To Hell The Georgia!\"\n",
        "print(str3.istitle()) #str3 = \"TO HELL WITH GEORGIA!\"\n",
        "print(str6.istitle())\n",
        "print(str7.istitle())"
      ],
      "metadata": {
        "id": "f8LISMCaxsuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isalpha()\n",
        "istitle() returns True if all the characters in the string are alphabetic"
      ],
      "metadata": {
        "id": "VzU0Y1IOjUBd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1O17oQ2XKcT"
      },
      "outputs": [],
      "source": [
        "#isalpha()\n",
        "str1 = \"To Hell With Georgia!\"\n",
        "str2 = \"!\"\n",
        "str3 = \"THWG\"\n",
        "print(str1.isalpha())\n",
        "print(str2.isalpha())\n",
        "print(str3.isalpha())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isdigit()\n",
        "isdigit() returns True if all the characters in the string are digits. Unicodes count as digits."
      ],
      "metadata": {
        "id": "oQ2MeeUcjUvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#isdigit() returns true if all characters in the string are digits\n",
        "#unicode is the encoding standard of assigning each letter, digit, or symbol a unique numeric value\n",
        "nstr1 = \"\\u0030\" #▲\n",
        "nstr2 = \"\\u00B2\" #☻\n",
        "nstr3 = \"\\u00BD\" #½\n",
        "nstr4 = '\\u00B23455' #☻3455\n",
        "nstr5 = \"ABC\"\n",
        "nstr6 = \" \"\n",
        "nstr7 = \"☻\"\n",
        "nstr8 = \"1234567\"\n",
        "nstr9 = \"½\"\n",
        "nstr10 = \"12.34\"\n",
        "\n",
        "print(nstr1.isdigit())\n",
        "print(nstr2.isdigit())\n",
        "print(nstr3.isdigit())\n",
        "print(nstr4.isdigit())\n",
        "print(nstr5.isdigit())\n",
        "print(nstr6.isdigit())\n",
        "print(nstr7.isdigit())\n",
        "print(nstr8.isdigit())\n",
        "print(nstr9.isdigit())\n",
        "print(nstr10.isdigit())"
      ],
      "metadata": {
        "id": "wux_EQikYsma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isnumeric()\n",
        "isnumeric() return True if all characters in the string are numeric. Unicodes count as numeric."
      ],
      "metadata": {
        "id": "_RJSoVSejVgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#isnumeric()\n",
        "nstr1 = \"\\u0030\" #▲\n",
        "nstr2 = \"\\u00B2\" #☻\n",
        "nstr3 = \"\\u00BD\" #½\n",
        "nstr4 = '\\u00B23455' #☻3455\n",
        "nstr5 = \"ABC\"\n",
        "nstr6 = \" \"\n",
        "nstr7 = \"☻\"\n",
        "nstr8 = \"1234567\"\n",
        "nstr9 = \"½\"\n",
        "nstr10 = \"12.34\"\n",
        "\n",
        "print(nstr1.isnumeric())\n",
        "print(nstr2.isnumeric())\n",
        "print(nstr3.isnumeric())\n",
        "print(nstr4.isnumeric())\n",
        "print(nstr5.isnumeric())\n",
        "print(nstr6.isnumeric())\n",
        "print(nstr7.isnumeric())\n",
        "print(nstr8.isnumeric())\n",
        "print(nstr9.isnumeric())\n",
        "print(nstr10.isnumeric())"
      ],
      "metadata": {
        "id": "tC27GhUHdneB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isdecimal()\n",
        "isdecimal() return True if the string represents a decimal"
      ],
      "metadata": {
        "id": "q0xcYWRejWUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#isdecimal() returns true if string represents a decimal\n",
        "nstr1 = \"\\u0030\" #▲\n",
        "nstr2 = \"\\u00B2\" #☻\n",
        "nstr3 = \"\\u00BD\" #½\n",
        "nstr4 = '\\u00B23455' #☻3455\n",
        "nstr5 = \"ABC\"\n",
        "nstr6 = \" \"\n",
        "nstr7 = \"☻\"\n",
        "nstr8 = \"1234567\"\n",
        "nstr9 = \"½\"\n",
        "nstr10 = \"12.34\"\n",
        "\n",
        "print(nstr1.isdecimal())\n",
        "print(nstr2.isdecimal())\n",
        "print(nstr3.isdecimal())\n",
        "print(nstr4.isdecimal())\n",
        "print(nstr5.isdecimal())\n",
        "print(nstr6.isdecimal())\n",
        "print(nstr7.isdecimal())\n",
        "print(nstr8.isdecimal())\n",
        "print(nstr9.isdecimal())\n",
        "print(nstr10.isdecimal())"
      ],
      "metadata": {
        "id": "o65uTczPfxva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### isalnum()\n",
        "isalnum() return True if all characters in the string are alphanumeric."
      ],
      "metadata": {
        "id": "mmTjcwdNjW1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#isalnum() returns true if all characters in the string are alphanumeric\n",
        "anstr1 = \"ABC\"\n",
        "anstr2 = \"THWG!\"\n",
        "anstr3 = \"A Cheese Cat\"\n",
        "anstr4 = \"\\u0030\"\n",
        "anstr5 = \"\\u00B2\"\n",
        "anstr6 = \"\\u00BD\"\n",
        "anstr7 = \"\\u00B23455\"\n",
        "anstr8 = \"☻\"\n",
        "anstr9 = \"½\"\n",
        "anstr10 = \"12.34\"\n",
        "anstr11 = \"1234\"\n",
        "\n",
        "print(anstr1.isalnum())\n",
        "print(anstr2.isalnum())\n",
        "print(anstr3.isalnum())\n",
        "print(anstr4.isalnum())\n",
        "print(anstr5.isalnum())\n",
        "print(anstr6.isalnum())\n",
        "print(anstr7.isalnum())\n",
        "print(anstr8.isalnum())\n",
        "print(anstr9.isalnum())\n",
        "print(anstr10.isalnum())\n",
        "print(anstr11.isalnum())"
      ],
      "metadata": {
        "id": "zMUBCZjOgKwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## String Operations"
      ],
      "metadata": {
        "id": "SYuF9GYZh6i4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### upper()\n",
        "Earlier, we went over lower(), so now let's do upper(). upper() returns the uppercase string from the given string."
      ],
      "metadata": {
        "id": "lpgOhsuhvh0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We have already gone over .lower() earlier when tokenizing, now let's do .upper()\n",
        "data.upper()"
      ],
      "metadata": {
        "id": "FQbktbc9iBAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### title()\n",
        "title() returns the titled version of the string, so every first letter of all the words in each string is now capitalized."
      ],
      "metadata": {
        "id": "lc5jcTISvikM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#title()\n",
        "strt = \"georgia tech yellow jackets\"\n",
        "strt.title()"
      ],
      "metadata": {
        "id": "7KhGN9w9icUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### titlecase()\n",
        "Since the title() function sometimes doesn't work properly as shown in the below examples, we write our own titlecase() method to fix that."
      ],
      "metadata": {
        "id": "3bKIVvMfvjF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#titlecase()\n",
        "strtc = \"georgia tech's yellow jackets\"\n",
        "print(strtc.title())\n",
        "print(strtc.capitalize())\n",
        "#we have to define a function to fix this issue\n",
        "#re library is used to check for given patterns in strings\n",
        "import re\n",
        "def titlecase(s):\n",
        "    return re.sub(\n",
        "        r\"[A-Za-z]+('[A-Za-z]+)?\",\n",
        "        lambda word: word.group(0).capitalize(),\n",
        "        s)\n",
        "    \n",
        "strtc=titlecase(strtc)\n",
        "print(strtc)"
      ],
      "metadata": {
        "id": "FkoccZyXizFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### split()\n",
        "split() returns a list of all the words in a string in order from left to right."
      ],
      "metadata": {
        "id": "w5fMGHZevj14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split()\n",
        "print(data.split())"
      ],
      "metadata": {
        "id": "gW0IyyOBkIP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import re\n",
        "print(re.split(\"\\s\",data))\n",
        "print(re.split(\"\\s\",data, 3))"
      ],
      "metadata": {
        "id": "R7bqH1Qx82Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitlines()\n",
        "splitlines() splits a string at any line breaks and returns them in a list."
      ],
      "metadata": {
        "id": "p3XYJg52vk72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitlines()\n",
        "splistr = \"Georgia Tech\\nYellow Jackets\"\n",
        "print(splistr)\n",
        "print(splistr.splitlines())"
      ],
      "metadata": {
        "id": "W6yRBIJ5k05x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sub()\n",
        "sub() returns a string where it replaces a string value with another string value."
      ],
      "metadata": {
        "id": "_lSsXxc2vlcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sub()\n",
        "#import re\n",
        "print(re.sub(\"\\s\", \"#\", data))\n",
        "print(re.sub(\"\\s\", \"#\", data, 2))"
      ],
      "metadata": {
        "id": "QJzL01_49ama"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### join()\n",
        "join() returns a string that connects a list of strings or every word in a string with a value."
      ],
      "metadata": {
        "id": "HO9KWRk0vl5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#join()\n",
        "joinsplit = data.split()\n",
        "print(\" \".join(joinsplit))\n",
        "print(\"$$$\".join(joinsplit))\n",
        "joinstring = \"abcdef\"\n",
        "print(\"$\".join(joinstring))\n",
        "joinstring2 = \" abcdef \"\n",
        "print(\"$\".join(joinstring2))\n",
        "\n",
        "joinList = ['ab','cd','ef']\n",
        "print(\"\".join(joinList))"
      ],
      "metadata": {
        "id": "2YqEJO-YlSZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### strip()\n",
        "strip() removes any leading and trailing spaces in a string and returns the string."
      ],
      "metadata": {
        "id": "KbXW11BBvmae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#strip()\n",
        "stripstr = \"         like          \"\n",
        "stripstr2 = stripstr.strip()\n",
        "print(stripstr2)\n",
        "print(\"I\", stripstr2, \"cheese.\")\n",
        "print(\"I\",\"like\",\"cheese.\")"
      ],
      "metadata": {
        "id": "Deqyz45ip8R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rstrip()\n",
        "rstrip() removes all the occurances of trailing given chars in a string and returns the string."
      ],
      "metadata": {
        "id": "rrB9rD9lvm45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rstrip(values)\n",
        "rstripstr = \"cheese,,,,,ssqqqww.....\"\n",
        "\n",
        "rstripstr2 = rstripstr.rstrip(\",.qsw\")\n",
        "print(rstripstr2)\n",
        "rstripstr3 = data.rstrip(\"a\")\n",
        "print(rstripstr3)"
      ],
      "metadata": {
        "id": "_1QXaj44rwZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### find()\n",
        "find() returns the index of the first occurance of a given string in a larger string or in a given range of a larger string."
      ],
      "metadata": {
        "id": "KPm2aCJ-vnUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find(value, start, end)\n",
        "print(data.find(\"Paramount\"))\n",
        "print(data.find(\"New York\"))\n",
        "print(data.find(\"are\"))\n",
        "print(data.find(\"are\", 35))\n",
        "print(data.find(\"Atlanta\", 5, 25))"
      ],
      "metadata": {
        "id": "kcuCjB4Fs36L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rfind()\n",
        "rfind() returns the index of the last occurance of a given string in a larger string or in a given range of a larger string."
      ],
      "metadata": {
        "id": "a5GzMpwtvn7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rfind(value, start, end)\n",
        "print(data.rfind(\"are\"))\n",
        "print(data.rfind(\"are\", 0, 40))\n",
        "print(data.rfind(\"are\", 0 ,8))\n",
        "print(data.rfind(\"are\", 0 ,2450))"
      ],
      "metadata": {
        "id": "NAjU-exXwR2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### replace()\n",
        "replace() find occurances in a string, replaces them, and then returns the string"
      ],
      "metadata": {
        "id": "Hv4c4_aQvoYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace(ogvalue, newvalue)\n",
        "print(data.replace(\"David\", \"Hiccup\"))\n",
        "#data = data.replace(\"David\", \"Hiccup\")"
      ],
      "metadata": {
        "id": "cueiI90ywl6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### search()\n",
        "search() returns True if there is a match anywhere in the string"
      ],
      "metadata": {
        "id": "_DiugUb2ZNAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#search()\n",
        "#import re\n",
        "\n",
        "print(re.search(\"in\",data))\n",
        "print(re.search(\"in\",data).start())\n",
        "print(re.search(\"let's go\",str1))"
      ],
      "metadata": {
        "id": "Y5RW3HJK8A2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### match()\n",
        "match() return True if there is a match at the beginning of the string"
      ],
      "metadata": {
        "id": "sBCqr4tKZeHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#search()\n",
        "#import re\n",
        "print(re.match(\"in\",data))\n",
        "print(re.match(\"Once\",data))\n",
        "print(re.match(\"Once\",data).start())"
      ],
      "metadata": {
        "id": "ZQSaDp7bZfLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Georgia Tech Data Visualization Lab 2022 - SR"
      ],
      "metadata": {
        "id": "4UMdnLg6KAm4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}